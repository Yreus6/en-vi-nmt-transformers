{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T18:57:30.499818600Z",
     "start_time": "2023-10-29T18:57:30.480817Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.transformers.seq2seq_trans import seq2seq_trans\n",
    "from models.transformers.utils import DEVICE, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class obj(object):\n",
    "    def __init__(self, d):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(k, (list, tuple)):\n",
    "                setattr(self, k, [obj(x) if isinstance(x, dict) else x for x in v])\n",
    "            else:\n",
    "                setattr(self, k, obj(v) if isinstance(v, dict) else v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T18:57:30.508818100Z",
     "start_time": "2023-10-29T18:57:30.488817400Z"
    }
   },
   "id": "77e667ab4566db80"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2SeqTransformer(\n  (transformer): Transformer(\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-5): 6 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): TransformerDecoder(\n      (layers): ModuleList(\n        (0-5): 6 x TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (generator): Linear(in_features=512, out_features=16000, bias=True)\n  (src_tok_emb): TokenEmbedding(\n    (embedding): Embedding(16000, 512)\n  )\n  (tgt_tok_emb): TokenEmbedding(\n    (embedding): Embedding(16000, 512)\n  )\n  (positional_encoding): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = obj({\n",
    "    'src_vocab_path': '../vocab/iwslt15/vocab.en.json',\n",
    "    'tgt_vocab_path': '../vocab/iwslt15/vocab.vi.json',\n",
    "    'src_vocab_size': 16000,\n",
    "    'tgt_vocab_size': 16000,\n",
    "    'model_file': '../checkpoints/1027-233555/best_model.pth',\n",
    "    'beam_search': True,\n",
    "    'beam_size': 5,\n",
    "    'max_decoding_time_step': 70,\n",
    "    'temperature': 1.1\n",
    "})\n",
    "\n",
    "model = seq2seq_trans(args)\n",
    "model.eval()\n",
    "model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T18:57:31.812760900Z",
     "start_time": "2023-10-29T18:57:30.502822500Z"
    }
   },
   "id": "5fdddd013e7868ac"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tôi phải bảo_vệ dự_án của mình .']\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    outputs = translate(model, ['Today I must defend my project'], args)\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T18:59:37.998738300Z",
     "start_time": "2023-10-29T18:59:37.524048300Z"
    }
   },
   "id": "dc7aaed0460e5c8d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T18:57:32.186681300Z",
     "start_time": "2023-10-29T18:57:32.134539Z"
    }
   },
   "id": "d866833eb78f7cd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
